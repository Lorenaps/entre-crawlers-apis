# Entre APIs e Crawlers: Como sobreviver quando a informação não está em um .csv


Workshop para o [CODA.BR 2019](https://coda.escoladedados.org/).

O objetivo desse workshop é introduzir o acesso a API’s (Application Programming Interface) que são uma espécie de interface com os dados de determinada aplicação, a exemplo da API do Github e da câmara dos deputados, bem como introduzir a utilização da ferramenta Scrapy para o desenvolvimento de crawlers.

#### Referências sobre o workshop:
- [News API](https://newsapi.org/s/google-news-br-api)
- [Google News](https://news.google.com/?hl=pt-BR&gl=BR&ceid=BR:pt-419)
- [Scrapy](https://scrapy.org/)
- [Documentação Scrapy](https://docs.scrapy.org/en/latest/)
- [API Câmara Municipal de São Paulo](http://splegisws.camara.sp.gov.br/ws/ws2.asmx)
- [Utilizando o Scrapy do Python para monitoramento em sites de notícias (Web Crawler) - ](https://medium.com/@marlessonsantana/utilizando-o-scrapy-do-python-para-monitoramento-em-sites-de-not%C3%ADcias-web-crawler-ebdf7f1e4966)

#### Referências de materiais de outras edições do CODABR:
- [Iluminando o mar de dados - Uma introdução a Python para análise de dados - Caroline Dantas](https://github.com/Caaddss/coda.br_workshop/blob/master/Coda.br.ipynb)
- [Análise de Dados Públicos com Pandas (Básico Python + Pandas) - Fernando Massanouri](https://www.dropbox.com/s/84jveh6gp1m0579/masanoripybr14.txt?dl=0)
- [Todas as apresentações do Coda.Br 2018 reunidas em um só lugar](https://escoladedados.org/2018/11/apresentacoes-codabr-2018/)
